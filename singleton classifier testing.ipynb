{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from csv import DictReader, DictWriter\n",
    "from utils.data_helper import get_markable_dataframe, get_embedding_variables\n",
    "from functools import reduce\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(26061997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_indexes_file_path = 'helper_files/embedding/embedding_indexes.txt'\n",
    "indexed_embedding_file_path = 'helper_files/embedding/indexed_embedding.txt'\n",
    "\n",
    "word_vector, embedding_matrix, idx_by_word, word_by_idx = get_embedding_variables(embedding_indexes_file_path, indexed_embedding_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_pronoun</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>is_proper_name</th>\n",
       "      <th>is_first_person</th>\n",
       "      <th>previous_words</th>\n",
       "      <th>next_words</th>\n",
       "      <th>is_singleton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>[1263, 1264, 1968, 1395]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[999, 379, 1161, 213, 27, 1263, 1969, 1188, 14...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1917</td>\n",
       "      <td>[213]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1263, 1264, 1968, 1395, 999, 379, 1161]</td>\n",
       "      <td>[27, 1263, 1969, 1188, 1470, 25, 1161, 63, 424...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1918</td>\n",
       "      <td>[1263, 1969, 1188]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1263, 1264, 1968, 1395, 999, 379, 1161, 213, 27]</td>\n",
       "      <td>[1470, 25, 1161, 63, 424, 1223, 25, 1415, 1161...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1919</td>\n",
       "      <td>[1470, 25, 1161]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1968, 1395, 999, 379, 1161, 213, 27, 1263, 19...</td>\n",
       "      <td>[63, 424, 1223, 25, 1415, 1161, 876, 344, 213,...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1920</td>\n",
       "      <td>[424]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1161, 213, 27, 1263, 1969, 1188, 1470, 25, 11...</td>\n",
       "      <td>[1223, 25, 1415, 1161, 876, 344, 213, 406, 122...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                      text  is_pronoun                     entity_type  \\\n",
       "0  1916  [1263, 1264, 1968, 1395]           0  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0]   \n",
       "1  1917                     [213]           1  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]   \n",
       "2  1918        [1263, 1969, 1188]           0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]   \n",
       "3  1919          [1470, 25, 1161]           0  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0]   \n",
       "4  1920                     [424]           0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "   is_proper_name  is_first_person  \\\n",
       "0               1                0   \n",
       "1               0                0   \n",
       "2               1                0   \n",
       "3               0                0   \n",
       "4               0                0   \n",
       "\n",
       "                                      previous_words  \\\n",
       "0                                                 []   \n",
       "1           [1263, 1264, 1968, 1395, 999, 379, 1161]   \n",
       "2  [1263, 1264, 1968, 1395, 999, 379, 1161, 213, 27]   \n",
       "3  [1968, 1395, 999, 379, 1161, 213, 27, 1263, 19...   \n",
       "4  [1161, 213, 27, 1263, 1969, 1188, 1470, 25, 11...   \n",
       "\n",
       "                                          next_words is_singleton  \n",
       "0  [999, 379, 1161, 213, 27, 1263, 1969, 1188, 14...   [1.0, 0.0]  \n",
       "1  [27, 1263, 1969, 1188, 1470, 25, 1161, 63, 424...   [1.0, 0.0]  \n",
       "2  [1470, 25, 1161, 63, 424, 1223, 25, 1415, 1161...   [1.0, 0.0]  \n",
       "3  [63, 424, 1223, 25, 1415, 1161, 876, 344, 213,...   [0.0, 1.0]  \n",
       "4  [1223, 25, 1415, 1161, 876, 344, 213, 406, 122...   [0.0, 1.0]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_testing_file_path = \"data/testing/markables.csv\"\n",
    "\n",
    "data = get_markable_dataframe(data_testing_file_path, word_vector, idx_by_word)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 10\n",
    "max_prev_words_length = 10\n",
    "max_next_words_length = 10\n",
    "\n",
    "data_text = pad_sequences(data.text, maxlen=max_text_length, padding='post')\n",
    "data_previous_words = pad_sequences(data.previous_words.map(lambda seq: seq[(-1*max_prev_words_length):]), maxlen=max_prev_words_length, padding='pre')\n",
    "data_next_words = pad_sequences(data.next_words.map(lambda seq: seq[:max_next_words_length]), maxlen=max_next_words_length, padding='post')\n",
    "data_syntactic = data[['is_pronoun', 'entity_type', 'is_proper_name', 'is_first_person']]\n",
    "\n",
    "data_syntactic = np.array(list(map(lambda p: reduce(lambda x,y: x + y, [i if type(i) is list else [i] for i in p]), data_syntactic.values)))\n",
    "label = np.vstack(data.is_singleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0314 11:24:22.308352 140304210511680 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:111: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0314 11:24:22.309836 140304210511680 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:135: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0314 11:24:22.310751 140304210511680 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:96: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0314 11:24:22.313545 140304210511680 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:96: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0314 11:24:22.314543 140304210511680 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1253: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "words_model = load_model('models/singleton_classifiers/words.model')\n",
    "context_model = load_model('models/singleton_classifiers/context.model')\n",
    "syntactic_model = load_model('models/singleton_classifiers/syntactic.model')\n",
    "words_context_model = load_model('models/singleton_classifiers/words_context.model')\n",
    "words_syntactic_model = load_model('models/singleton_classifiers/words_syntactic.model')\n",
    "context_syntactic_model = load_model('models/singleton_classifiers/context_syntactic.model')\n",
    "words_context_syntactic_model = load_model('models/singleton_classifiers/words_context_syntactic.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(output, threshold=0.5):\n",
    "    return list(map(lambda x: 1 if x[1] > threshold else 0, output))\n",
    "\n",
    "def evaluate(label, pred, threshold=0.5):\n",
    "    label = get_classes(label)\n",
    "    pred = get_classes(pred, threshold)\n",
    "    \n",
    "    print('threshold %f:' % threshold)\n",
    "    print(classification_report(label, pred))\n",
    "    print('accuracy: %f' % accuracy_score(label, pred))\n",
    "\n",
    "def evaluate_all(label, pred):\n",
    "    for i in range(1, 10):\n",
    "        evaluate(label, pred, i*0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pred = words_model.predict([data_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.33      0.47       105\n",
      "          1       0.91      0.99      0.95       693\n",
      "\n",
      "avg / total       0.89      0.90      0.88       798\n",
      "\n",
      "accuracy: 0.901003\n",
      "threshold 0.200000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.35      0.49       105\n",
      "          1       0.91      0.99      0.95       693\n",
      "\n",
      "avg / total       0.90      0.90      0.89       798\n",
      "\n",
      "accuracy: 0.903509\n",
      "threshold 0.300000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.36      0.49       105\n",
      "          1       0.91      0.98      0.94       693\n",
      "\n",
      "avg / total       0.89      0.90      0.88       798\n",
      "\n",
      "accuracy: 0.899749\n",
      "threshold 0.400000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.36      0.48       105\n",
      "          1       0.91      0.98      0.94       693\n",
      "\n",
      "avg / total       0.88      0.90      0.88       798\n",
      "\n",
      "accuracy: 0.897243\n",
      "threshold 0.500000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.63      0.61       105\n",
      "          1       0.94      0.94      0.94       693\n",
      "\n",
      "avg / total       0.90      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.895990\n",
      "threshold 0.600000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.65      0.63       105\n",
      "          1       0.95      0.94      0.94       693\n",
      "\n",
      "avg / total       0.90      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.898496\n",
      "threshold 0.700000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.66      0.63       105\n",
      "          1       0.95      0.94      0.94       693\n",
      "\n",
      "avg / total       0.90      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.898496\n",
      "threshold 0.800000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.70      0.64       105\n",
      "          1       0.95      0.93      0.94       693\n",
      "\n",
      "avg / total       0.91      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.898496\n",
      "threshold 0.900000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.73      0.63       105\n",
      "          1       0.96      0.91      0.93       693\n",
      "\n",
      "avg / total       0.90      0.89      0.89       798\n",
      "\n",
      "accuracy: 0.888471\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, words_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_pred = context_model.predict([data_previous_words, data_next_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.22      0.33       105\n",
      "          1       0.89      0.98      0.94       693\n",
      "\n",
      "avg / total       0.86      0.88      0.86       798\n",
      "\n",
      "accuracy: 0.882206\n",
      "threshold 0.200000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.37      0.46       105\n",
      "          1       0.91      0.96      0.93       693\n",
      "\n",
      "avg / total       0.87      0.88      0.87       798\n",
      "\n",
      "accuracy: 0.883459\n",
      "threshold 0.300000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.38      0.45       105\n",
      "          1       0.91      0.95      0.93       693\n",
      "\n",
      "avg / total       0.86      0.88      0.87       798\n",
      "\n",
      "accuracy: 0.875940\n",
      "threshold 0.400000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.40      0.45       105\n",
      "          1       0.91      0.94      0.93       693\n",
      "\n",
      "avg / total       0.86      0.87      0.86       798\n",
      "\n",
      "accuracy: 0.869674\n",
      "threshold 0.500000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.42      0.45       105\n",
      "          1       0.91      0.93      0.92       693\n",
      "\n",
      "avg / total       0.86      0.86      0.86       798\n",
      "\n",
      "accuracy: 0.863409\n",
      "threshold 0.600000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.43      0.43       105\n",
      "          1       0.91      0.92      0.91       693\n",
      "\n",
      "avg / total       0.85      0.85      0.85       798\n",
      "\n",
      "accuracy: 0.852130\n",
      "threshold 0.700000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.44      0.42       105\n",
      "          1       0.91      0.90      0.91       693\n",
      "\n",
      "avg / total       0.85      0.84      0.84       798\n",
      "\n",
      "accuracy: 0.840852\n",
      "threshold 0.800000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.39      0.48      0.43       105\n",
      "          1       0.92      0.89      0.90       693\n",
      "\n",
      "avg / total       0.85      0.83      0.84       798\n",
      "\n",
      "accuracy: 0.833333\n",
      "threshold 0.900000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.51      0.44       105\n",
      "          1       0.92      0.87      0.90       693\n",
      "\n",
      "avg / total       0.85      0.82      0.84       798\n",
      "\n",
      "accuracy: 0.824561\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, context_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_pred = syntactic_model.predict([data_syntactic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       105\n",
      "          1       0.87      1.00      0.93       693\n",
      "\n",
      "avg / total       0.75      0.87      0.81       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.200000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       105\n",
      "          1       0.87      1.00      0.93       693\n",
      "\n",
      "avg / total       0.75      0.87      0.81       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.300000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       105\n",
      "          1       0.87      1.00      0.93       693\n",
      "\n",
      "avg / total       0.75      0.87      0.81       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.400000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       105\n",
      "          1       0.87      1.00      0.93       693\n",
      "\n",
      "avg / total       0.75      0.87      0.81       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.500000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       105\n",
      "          1       0.87      1.00      0.93       693\n",
      "\n",
      "avg / total       0.75      0.86      0.81       798\n",
      "\n",
      "accuracy: 0.864662\n",
      "threshold 0.600000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.30      0.24      0.27       105\n",
      "          1       0.89      0.92      0.90       693\n",
      "\n",
      "avg / total       0.81      0.83      0.82       798\n",
      "\n",
      "accuracy: 0.827068\n",
      "threshold 0.700000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.28      0.30       105\n",
      "          1       0.89      0.91      0.90       693\n",
      "\n",
      "avg / total       0.82      0.83      0.82       798\n",
      "\n",
      "accuracy: 0.830827\n",
      "threshold 0.800000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.52      0.44       105\n",
      "          1       0.92      0.87      0.90       693\n",
      "\n",
      "avg / total       0.85      0.83      0.84       798\n",
      "\n",
      "accuracy: 0.827068\n",
      "threshold 0.900000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.53      0.44       105\n",
      "          1       0.92      0.87      0.90       693\n",
      "\n",
      "avg / total       0.85      0.82      0.84       798\n",
      "\n",
      "accuracy: 0.823308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, syntactic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_pred = words_context_model.predict([data_text, data_previous_words, data_next_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.41      0.56       105\n",
      "          1       0.92      0.99      0.95       693\n",
      "\n",
      "avg / total       0.91      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.914787\n",
      "threshold 0.200000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.49      0.62       105\n",
      "          1       0.93      0.99      0.96       693\n",
      "\n",
      "avg / total       0.92      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.921053\n",
      "threshold 0.300000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.55      0.64       105\n",
      "          1       0.93      0.97      0.95       693\n",
      "\n",
      "avg / total       0.91      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.918546\n",
      "threshold 0.400000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.55      0.64       105\n",
      "          1       0.93      0.97      0.95       693\n",
      "\n",
      "avg / total       0.91      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.918546\n",
      "threshold 0.500000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.55      0.64       105\n",
      "          1       0.93      0.97      0.95       693\n",
      "\n",
      "avg / total       0.91      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.917293\n",
      "threshold 0.600000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.57      0.65       105\n",
      "          1       0.94      0.97      0.95       693\n",
      "\n",
      "avg / total       0.91      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.919799\n",
      "threshold 0.700000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.59      0.67       105\n",
      "          1       0.94      0.97      0.96       693\n",
      "\n",
      "avg / total       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.922306\n",
      "threshold 0.800000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.61      0.67       105\n",
      "          1       0.94      0.97      0.96       693\n",
      "\n",
      "avg / total       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.921053\n",
      "threshold 0.900000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.66      0.70       105\n",
      "          1       0.95      0.97      0.96       693\n",
      "\n",
      "avg / total       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.924812\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, words_context_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Syntactic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_syntactic_pred = words_syntactic_model.predict([data_text, data_syntactic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.38      0.53       105\n",
      "          1       0.91      0.99      0.95       693\n",
      "\n",
      "avg / total       0.91      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.911028\n",
      "threshold 0.200000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.39      0.54       105\n",
      "          1       0.91      0.99      0.95       693\n",
      "\n",
      "avg / total       0.91      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.912281\n",
      "threshold 0.300000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.40      0.54       105\n",
      "          1       0.92      0.99      0.95       693\n",
      "\n",
      "avg / total       0.90      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.909774\n",
      "threshold 0.400000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.44      0.57       105\n",
      "          1       0.92      0.98      0.95       693\n",
      "\n",
      "avg / total       0.91      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.912281\n",
      "threshold 0.500000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.49      0.59       105\n",
      "          1       0.93      0.98      0.95       693\n",
      "\n",
      "avg / total       0.90      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.911028\n",
      "threshold 0.600000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.73      0.69       105\n",
      "          1       0.96      0.94      0.95       693\n",
      "\n",
      "avg / total       0.92      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.912281\n",
      "threshold 0.700000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.73      0.69       105\n",
      "          1       0.96      0.94      0.95       693\n",
      "\n",
      "avg / total       0.92      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.912281\n",
      "threshold 0.800000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.76      0.70       105\n",
      "          1       0.96      0.94      0.95       693\n",
      "\n",
      "avg / total       0.92      0.91      0.92       798\n",
      "\n",
      "accuracy: 0.914787\n",
      "threshold 0.900000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.77      0.68       105\n",
      "          1       0.96      0.92      0.94       693\n",
      "\n",
      "avg / total       0.92      0.90      0.91       798\n",
      "\n",
      "accuracy: 0.903509\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, words_syntactic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context + Syntactic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_syntactic_pred = context_syntactic_model.predict([data_previous_words, data_next_words, data_syntactic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.21      0.32       105\n",
      "          1       0.89      0.98      0.93       693\n",
      "\n",
      "avg / total       0.86      0.88      0.85       798\n",
      "\n",
      "accuracy: 0.880952\n",
      "threshold 0.200000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.30      0.41       105\n",
      "          1       0.90      0.98      0.94       693\n",
      "\n",
      "avg / total       0.87      0.89      0.87       798\n",
      "\n",
      "accuracy: 0.887218\n",
      "threshold 0.300000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.33      0.44       105\n",
      "          1       0.91      0.97      0.94       693\n",
      "\n",
      "avg / total       0.87      0.89      0.87       798\n",
      "\n",
      "accuracy: 0.889724\n",
      "threshold 0.400000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.35      0.45       105\n",
      "          1       0.91      0.97      0.94       693\n",
      "\n",
      "avg / total       0.87      0.89      0.87       798\n",
      "\n",
      "accuracy: 0.888471\n",
      "threshold 0.500000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.36      0.46       105\n",
      "          1       0.91      0.97      0.94       693\n",
      "\n",
      "avg / total       0.87      0.89      0.87       798\n",
      "\n",
      "accuracy: 0.885965\n",
      "threshold 0.600000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.38      0.47       105\n",
      "          1       0.91      0.97      0.94       693\n",
      "\n",
      "avg / total       0.87      0.89      0.88       798\n",
      "\n",
      "accuracy: 0.888471\n",
      "threshold 0.700000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.41      0.50       105\n",
      "          1       0.92      0.96      0.94       693\n",
      "\n",
      "avg / total       0.88      0.89      0.88       798\n",
      "\n",
      "accuracy: 0.890977\n",
      "threshold 0.800000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.43      0.51       105\n",
      "          1       0.92      0.96      0.94       693\n",
      "\n",
      "avg / total       0.88      0.89      0.88       798\n",
      "\n",
      "accuracy: 0.890977\n",
      "threshold 0.900000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.45      0.51       105\n",
      "          1       0.92      0.95      0.94       693\n",
      "\n",
      "avg / total       0.88      0.89      0.88       798\n",
      "\n",
      "accuracy: 0.885965\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, context_syntactic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Context + Syntactic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_syntactic_pred = words_context_syntactic_model.predict([\n",
    "    data_text, data_previous_words, data_next_words, data_syntactic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.53      0.63       105\n",
      "          1       0.93      0.98      0.95       693\n",
      "\n",
      "avg / total       0.91      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.918546\n",
      "threshold 0.200000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.57      0.65       105\n",
      "          1       0.94      0.97      0.95       693\n",
      "\n",
      "avg / total       0.91      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.918546\n",
      "threshold 0.300000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.58      0.66       105\n",
      "          1       0.94      0.97      0.95       693\n",
      "\n",
      "avg / total       0.91      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.919799\n",
      "threshold 0.400000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.59      0.66       105\n",
      "          1       0.94      0.97      0.95       693\n",
      "\n",
      "avg / total       0.91      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.918546\n",
      "threshold 0.500000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.60      0.66       105\n",
      "          1       0.94      0.97      0.95       693\n",
      "\n",
      "avg / total       0.91      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.919799\n",
      "threshold 0.600000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.61      0.65       105\n",
      "          1       0.94      0.96      0.95       693\n",
      "\n",
      "avg / total       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.914787\n",
      "threshold 0.700000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.63      0.66       105\n",
      "          1       0.94      0.96      0.95       693\n",
      "\n",
      "avg / total       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.914787\n",
      "threshold 0.800000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.68      0.67       105\n",
      "          1       0.95      0.95      0.95       693\n",
      "\n",
      "avg / total       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.911028\n",
      "threshold 0.900000:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.70      0.67       105\n",
      "          1       0.95      0.94      0.95       693\n",
      "\n",
      "avg / total       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.909774\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, words_context_syntactic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Richer Markable Data with Predicted Singleton (for coreference resolution testing purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_data_testing_file_path = \"data/testing/markables_with_predicted_singleton.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_testing_file_path, \"r\") as orifile:\n",
    "    oricsv = DictReader(orifile)\n",
    "    \n",
    "    with open(rich_data_testing_file_path, \"w\") as newfile:\n",
    "        newcsv = DictWriter(newfile, fieldnames=oricsv.fieldnames)\n",
    "        \n",
    "        newcsv.writeheader()\n",
    "        \n",
    "        for row, is_singleton in zip(oricsv, get_classes(words_syntactic_pred, 0.8)):\n",
    "            newcsv.writerow({**row, 'is_singleton': is_singleton})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
