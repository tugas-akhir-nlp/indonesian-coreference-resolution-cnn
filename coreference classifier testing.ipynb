{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.data_helper import get_markable_dataframe, get_embedding_variables\n",
    "from model_builders.coreference_classifier import CoreferenceClassifierModelBuilder\n",
    "from functools import reduce\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from utils.clusterers import BestFirstClusterer, get_anaphora_scores_by_antecedent, ClosestFirstClusterer\n",
    "from utils.scorers import MUCScorer, B3Scorer, AverageScorer\n",
    "from utils.data_structures import UFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_indexes_file_path = 'helper_files/embedding/embedding_indexes.txt'\n",
    "indexed_embedding_file_path = 'helper_files/embedding/indexed_embedding.txt'\n",
    "\n",
    "word_vector, embedding_matrix, idx_by_word, word_by_idx = get_embedding_variables(embedding_indexes_file_path, indexed_embedding_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_pronoun</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>is_proper_name</th>\n",
       "      <th>is_first_person</th>\n",
       "      <th>previous_words</th>\n",
       "      <th>next_words</th>\n",
       "      <th>is_singleton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>[1263, 1264, 1968, 1395]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[999, 379, 1161, 213, 27, 1263, 1969, 1188, 14...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1917</td>\n",
       "      <td>[213]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1263, 1264, 1968, 1395, 999, 379, 1161]</td>\n",
       "      <td>[27, 1263, 1969, 1188, 1470, 25, 1161, 63, 424...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1918</td>\n",
       "      <td>[1263, 1969, 1188]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1263, 1264, 1968, 1395, 999, 379, 1161, 213, 27]</td>\n",
       "      <td>[1470, 25, 1161, 63, 424, 1223, 25, 1415, 1161...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1919</td>\n",
       "      <td>[1470, 25, 1161]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1968, 1395, 999, 379, 1161, 213, 27, 1263, 19...</td>\n",
       "      <td>[63, 424, 1223, 25, 1415, 1161, 876, 344, 213,...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1920</td>\n",
       "      <td>[424]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1161, 213, 27, 1263, 1969, 1188, 1470, 25, 11...</td>\n",
       "      <td>[1223, 25, 1415, 1161, 876, 344, 213, 406, 122...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                      text  is_pronoun                     entity_type  \\\n",
       "0  1916  [1263, 1264, 1968, 1395]           0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "1  1917                     [213]           1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "2  1918        [1263, 1969, 1188]           0  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
       "3  1919          [1470, 25, 1161]           0  [0, 0, 0, 0, 0, 0, 1, 0, 0, 1]   \n",
       "4  1920                     [424]           0  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]   \n",
       "\n",
       "   is_proper_name  is_first_person  \\\n",
       "0               1                0   \n",
       "1               0                0   \n",
       "2               1                0   \n",
       "3               0                0   \n",
       "4               0                0   \n",
       "\n",
       "                                      previous_words  \\\n",
       "0                                                 []   \n",
       "1           [1263, 1264, 1968, 1395, 999, 379, 1161]   \n",
       "2  [1263, 1264, 1968, 1395, 999, 379, 1161, 213, 27]   \n",
       "3  [1968, 1395, 999, 379, 1161, 213, 27, 1263, 19...   \n",
       "4  [1161, 213, 27, 1263, 1969, 1188, 1470, 25, 11...   \n",
       "\n",
       "                                          next_words is_singleton  \n",
       "0  [999, 379, 1161, 213, 27, 1263, 1969, 1188, 14...   [0.0, 1.0]  \n",
       "1  [27, 1263, 1969, 1188, 1470, 25, 1161, 63, 424...   [1.0, 0.0]  \n",
       "2  [1470, 25, 1161, 63, 424, 1223, 25, 1415, 1161...   [0.0, 1.0]  \n",
       "3  [63, 424, 1223, 25, 1415, 1161, 876, 344, 213,...   [0.0, 1.0]  \n",
       "4  [1223, 25, 1415, 1161, 876, 344, 213, 406, 122...   [0.0, 1.0]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markables = get_markable_dataframe(\"data/testing/markables_with_predicted_singleton.csv\", word_vector, idx_by_word)\n",
    "singletons = set(markables[markables['is_singleton'].map(lambda x: True if x[1] > 0 else False)]['id'])\n",
    "markables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1_id</th>\n",
       "      <th>m2_id</th>\n",
       "      <th>is_exact_match</th>\n",
       "      <th>is_words_match</th>\n",
       "      <th>is_substring</th>\n",
       "      <th>is_abbreviation</th>\n",
       "      <th>is_appositive</th>\n",
       "      <th>is_nearest_candidate</th>\n",
       "      <th>sentence_distance</th>\n",
       "      <th>word_distance</th>\n",
       "      <th>markable_distance</th>\n",
       "      <th>is_coreference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>1917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1916</td>\n",
       "      <td>1918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1916</td>\n",
       "      <td>1919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1916</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1916</td>\n",
       "      <td>1921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m1_id  m2_id  is_exact_match  is_words_match  is_substring  \\\n",
       "0   1916   1917               0               0             0   \n",
       "1   1916   1918               0               0             0   \n",
       "2   1916   1919               0               0             0   \n",
       "3   1916   1920               0               0             0   \n",
       "4   1916   1921               0               0             0   \n",
       "\n",
       "   is_abbreviation  is_appositive  is_nearest_candidate  sentence_distance  \\\n",
       "0                0              0                     1                  0   \n",
       "1                0              0                     0                  0   \n",
       "2                0              0                     0                  0   \n",
       "3                0              0                     0                  0   \n",
       "4                0              0                     0                  0   \n",
       "\n",
       "   word_distance  markable_distance  is_coreference  \n",
       "0              3                  1               1  \n",
       "1              5                  2               0  \n",
       "2              8                  3               0  \n",
       "3             12                  4               0  \n",
       "4             13                  5               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = pd.read_csv(\"data/testing/mention_pairs.csv\")\n",
    "\n",
    "label = np.vstack(to_categorical(pairs.is_coreference, num_classes=2))\n",
    "label_chains = ClosestFirstClusterer().get_chains(get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, label))\n",
    "\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 10\n",
    "max_prev_words_length = 10\n",
    "max_next_words_length = 10\n",
    "\n",
    "def get_data(markable_ids):\n",
    "    indices = reduce(lambda a, b: a + [b], map(lambda a: markables.index[markables['id'] == a].tolist()[0], markable_ids), [])\n",
    "    data = markables.loc[indices]\n",
    "    \n",
    "    data_text = pad_sequences(data.text, maxlen=max_text_length, padding='post')\n",
    "    data_previous_words = pad_sequences(data.previous_words.map(lambda seq: seq[(-1*max_prev_words_length):]), maxlen=max_prev_words_length, padding='pre')\n",
    "    data_next_words = pad_sequences(data.next_words.map(lambda seq: seq[:max_next_words_length]), maxlen=max_next_words_length, padding='post')\n",
    "    data_syntactic = data[['is_pronoun', 'entity_type', 'is_proper_name', 'is_first_person']]\n",
    "\n",
    "    data_syntactic = np.array(list(map(lambda p: reduce(lambda x,y: x + y, [i if type(i) is list else [i] for i in p]), data_syntactic.values)))\n",
    "    is_singleton = np.vstack(data.is_singleton)\n",
    "    \n",
    "    return data_text, data_previous_words, data_next_words, data_syntactic, is_singleton\n",
    "\n",
    "def get_pair_data(markable_ids_1, markable_ids_2):\n",
    "    text_1, prev_1, next_1, syntactic_1, is_singleton_1 = get_data(markable_ids_1)\n",
    "    text_2, prev_2, next_2, syntactic_2, is_singleton_2 = get_data(markable_ids_2)\n",
    "    \n",
    "    return text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, is_singleton_1, is_singleton_2\n",
    "\n",
    "def get_relation_data(mention_pairs):\n",
    "    return mention_pairs[['is_exact_match', 'is_words_match', 'is_substring', 'is_abbreviation', 'is_appositive', 'is_nearest_candidate', 'sentence_distance', 'word_distance', 'markable_distance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Baseline Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUC:  (0.5544554455445545, 0.7272727272727273, 0.6292134831460674)\n",
      "B3:  (0.3124361294443262, 0.6732829670329671, 0.4268110965737344)\n",
      "Average:  (0.5280122898599009, 0.5280122898599009, 0.5280122898599009)\n"
     ]
    }
   ],
   "source": [
    "baseline_result_file_path = 'baseline/test_result.txt'\n",
    "\n",
    "baseline_ufds = UFDS()\n",
    "\n",
    "for m1, m2 in zip(pairs.m1_id, pairs.m2_id):\n",
    "    baseline_ufds.init_id(m1, m2)\n",
    "    \n",
    "for line in open(baseline_result_file_path, 'r').readlines():\n",
    "    line = line.split(', ')\n",
    "    baseline_ufds.join(int(line[0]), int(line[1]))\n",
    "\n",
    "baseline_chains = baseline_ufds.get_chain_list()\n",
    "\n",
    "print('MUC: ', MUCScorer().get_scores(baseline_chains, label_chains))\n",
    "print('B3: ', B3Scorer().get_scores(baseline_chains, label_chains))\n",
    "print('Average: ', AverageScorer([MUCScorer(), B3Scorer()]).get_scores(baseline_chains, label_chains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, is_singleton_1, is_singleton_2 = get_pair_data(pairs.m1_id, pairs.m2_id)\n",
    "relation = get_relation_data(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Budi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words + Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Improperly formatted model config.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7ba76827d857>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords_syntactic_model_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/coreference_classifiers/words_context_syntactic_budi_5.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ta-v2/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    228\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ta-v2/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    308\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m    309\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ta-v2/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ta-v2/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    171\u001b[0m             custom_objects=dict(\n\u001b[1;32m    172\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    174\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ta-v2/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mnode_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             \u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/ta-v2/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   1244\u001b[0m           \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Improperly formatted model config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minbound_layer_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m           \u001b[0madd_unprocessed_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Improperly formatted model config."
     ]
    }
   ],
   "source": [
    "words_syntactic_model_1 = load_model('models/coreference_classifiers/words_context_syntactic_budi_5.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23689/23689==============================] - 6s 248us/sample\n"
     ]
    }
   ],
   "source": [
    "syntactic_1_pred = words_syntactic_model_1.predict([text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, relation], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "predz = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, syntactic_1_pred)\n",
    "predz2 = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, syntactic_1_pred, singletons)\n",
    "labz = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_chains = BestFirstClusterer().get_chains(predz, threshold=0.005)\n",
    "pred_chains2 = BestFirstClusterer().get_chains(predz2, threshold=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.21241830065359477, 0.8441558441558441, 0.3394255874673629)\n",
      "(0.5978260869565217, 0.7142857142857143, 0.6508875739644971)\n",
      "\n",
      "(0.0807532311295752, 0.8297619047619047, 0.14718251731674847)\n",
      "(0.3842241349185793, 0.6573489010989012, 0.4849766730331626)\n"
     ]
    }
   ],
   "source": [
    "print(MUCScorer().get_scores(pred_chains, label_chains))\n",
    "print(MUCScorer().get_scores(pred_chains2, label_chains))\n",
    "print()\n",
    "print(B3Scorer().get_scores(pred_chains, label_chains))\n",
    "print(B3Scorer().get_scores(pred_chains2, label_chains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markable_text(idx):\n",
    "#     return {idx: (markables[markables['id'] == idx].text.values)}\n",
    "    return [word_by_idx[x] for x in markables[markables['id'] == idx].text.values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['bank', 'indonesia'],\n",
       "  ['bi'],\n",
       "  ['hartadi', 'a', 'sarwono'],\n",
       "  ['ia'],\n",
       "  ['hartadi'],\n",
       "  ['bi'],\n",
       "  ['hartadi'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['hartadi'],\n",
       "  ['nya'],\n",
       "  ['ia'],\n",
       "  ['nya'],\n",
       "  ['ansari'],\n",
       "  ['ansari']],\n",
       " [['menteri', 'keuangan', 'sri', 'mulyani'],\n",
       "  ['sri', 'mulyani'],\n",
       "  ['mulyani'],\n",
       "  ['mulyani']],\n",
       " [['aali'], ['nya'], ['direktur', 'aali'], ['santosa'], ['nya']],\n",
       " [['deputi', 'senior'],\n",
       "  ['bank', 'indonesia'],\n",
       "  ['bi'],\n",
       "  ['miranda', 's', 'goeltom'],\n",
       "  ['miranda'],\n",
       "  ['miranda'],\n",
       "  ['nya'],\n",
       "  ['nya']],\n",
       " [['deputi', 'gubernur', 'senior', 'bi'],\n",
       "  ['miranda', 's', 'goeltom'],\n",
       "  ['miranda'],\n",
       "  ['nya']],\n",
       " [['bank', 'mandiri'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['direktur', 'teknologi', 'dan', 'operasional', 'bank', 'mandiri'],\n",
       "  ['sasmita'],\n",
       "  ['dia'],\n",
       "  ['bank', 'mandiri'],\n",
       "  ['ia'],\n",
       "  ['nya'],\n",
       "  ['bank', 'mandiri'],\n",
       "  ['nya']],\n",
       " [['menteri', 'keuangan', 'sri', 'mulyani', 'indrawati'],\n",
       "  ['menko', 'perekonomian', 'boediono'],\n",
       "  ['nya'],\n",
       "  ['boediono'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya']],\n",
       " [['pefindo'], ['nya'], ['dia']],\n",
       " [['pt', 'tri', 'usaha', 'bhakti'], ['nya']],\n",
       " [['indonesia'],\n",
       "  ['adb'],\n",
       "  ['adb'],\n",
       "  ['nya'],\n",
       "  ['rm', 'dewo', 'broto', 'joko', 'p'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['adb'],\n",
       "  ['nya'],\n",
       "  ['dewo']],\n",
       " [['fitri', 'barnas'], ['nya'], ['ia']],\n",
       " [['pt', 'nibung', 'arthamulia'], ['pt', 'nibung', 'arthamulia']],\n",
       " [['anwar'],\n",
       "  ['nya'],\n",
       "  ['pemerintah'],\n",
       "  ['dpr'],\n",
       "  ['dpr'],\n",
       "  ['nya'],\n",
       "  ['dpr'],\n",
       "  ['nya'],\n",
       "  ['dia'],\n",
       "  ['nya'],\n",
       "  ['ia']],\n",
       " [['indonesia'],\n",
       "  ['fitch'],\n",
       "  ['nya'],\n",
       "  ['indonesia'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['fitch'],\n",
       "  ['nya']],\n",
       " [['nya'],\n",
       "  ['nya'],\n",
       "  ['jepang'],\n",
       "  ['pt', 'astra', 'otoparts'],\n",
       "  ['kartina', 'rahayu'],\n",
       "  ['dia'],\n",
       "  ['dia'],\n",
       "  ['nya'],\n",
       "  ['nya']],\n",
       " [['menkeu', 'sri', 'mulyani', 'indrawati'], ['dia']]]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[get_markable_text(b) for b in a] for a in pred_chains2 if len(a) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['deputi', 'gubernur'], ['bank', 'indonesia']],\n",
       " [['hartadi', 'a', 'sarwono'],\n",
       "  ['ia'],\n",
       "  ['hartadi'],\n",
       "  ['jakarta'],\n",
       "  ['hartadi'],\n",
       "  ['hartadi'],\n",
       "  ['kami'],\n",
       "  ['sekretaris', 'perusahaan', 'astra', 'otoparts'],\n",
       "  ['kartina', 'rahayu'],\n",
       "  ['dia'],\n",
       "  ['dia'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['menkeu', 'sri', 'mulyani', 'indrawati'],\n",
       "  ['dia']],\n",
       " [['ia'],\n",
       "  ['dirjend',\n",
       "   'industri',\n",
       "   'logam',\n",
       "   'mesin',\n",
       "   'tekstil',\n",
       "   'departemen',\n",
       "   'perindustrian',\n",
       "   'ansari',\n",
       "   'bukhari'],\n",
       "  ['ansari'],\n",
       "  ['ansari']],\n",
       " [['indonesia', 'investor', 'forum'], ['indonesia', 'investor', 'forum']],\n",
       " [['menteri', 'keuangan', 'sri', 'mulyani'],\n",
       "  ['sri', 'mulyani'],\n",
       "  ['mulyani'],\n",
       "  ['nya']],\n",
       " [['direktur', 'aali'],\n",
       "  ['santosa'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['deputi', 'senior'],\n",
       "  ['bank', 'indonesia'],\n",
       "  ['miranda', 's', 'goeltom'],\n",
       "  ['miranda'],\n",
       "  ['miranda'],\n",
       "  ['kami'],\n",
       "  ['nya'],\n",
       "  ['deputi', 'gubernur', 'senior', 'bi'],\n",
       "  ['miranda', 's', 'goeltom'],\n",
       "  ['miranda']],\n",
       " [['pertumbuhan', 'ekonomi', 'indonesia'],\n",
       "  ['pertumbuhan', 'ekonomi', 'indonesia'],\n",
       "  ['pertumbuhan', 'ekonomi', 'indonesia']],\n",
       " [['bank', 'mandiri'], ['bank', 'mandiri'], ['bank', 'mandiri']],\n",
       " [['nya'],\n",
       "  ['direktur', 'teknologi', 'dan', 'operasional', 'bank', 'mandiri'],\n",
       "  ['sasmita'],\n",
       "  ['dia'],\n",
       "  ['ia'],\n",
       "  ['kita'],\n",
       "  ['nya'],\n",
       "  ['menteri', 'keuangan', 'sri', 'mulyani', 'indrawati']],\n",
       " [['<angka>', 'dolar', 'as'], ['<angka>', 'dolar', 'as']],\n",
       " [['jurong', 'engineering', 'limited', 'of', 'singapore'], ['jel']],\n",
       " [['nya'],\n",
       "  ['menko', 'perekonomian', 'boediono'],\n",
       "  ['nya'],\n",
       "  ['boediono'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['pefindo'],\n",
       "  ['trje'],\n",
       "  ['analis', 'pefindo', 'ronald', 'hertanto'],\n",
       "  ['nya'],\n",
       "  ['dia'],\n",
       "  ['trje'],\n",
       "  ['trje'],\n",
       "  ['trje'],\n",
       "  ['nya']],\n",
       " [['adb'],\n",
       "  ['adb'],\n",
       "  ['sendiri'],\n",
       "  ['nya'],\n",
       "  ['direktur', 'pendanaan', 'luar', 'negeri', 'multilateral', 'bappenas'],\n",
       "  ['rm', 'dewo', 'broto', 'joko', 'p'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['plta', 'genyem'],\n",
       "  ['papua'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['adb'],\n",
       "  ['gorontalo'],\n",
       "  ['kita'],\n",
       "  ['nya'],\n",
       "  ['dewo'],\n",
       "  ['sekretaris', 'perusahaan', 'bakrie', 'sumatera', 'plantations', 'tbk'],\n",
       "  ['fitri', 'barnas'],\n",
       "  ['nya'],\n",
       "  ['ia']],\n",
       " [['pt', 'nibung', 'arthamulia'], ['pt', 'nibung', 'arthamulia']],\n",
       " [['pgas'], ['saham', 'pgas'], ['nya']],\n",
       " [['nya'],\n",
       "  ['dirjen',\n",
       "   'bea',\n",
       "   'dan',\n",
       "   'cukai',\n",
       "   'departemen',\n",
       "   'keuangan',\n",
       "   'anwar',\n",
       "   'suprijad'],\n",
       "  ['anwar', 'suprijad'],\n",
       "  ['anwar'],\n",
       "  ['nya'],\n",
       "  ['kita']],\n",
       " [['lembaga', 'pemeringkat', 'internasional', 'fitch', 'ratings'], ['fitch']],\n",
       " [['dpr'], ['dpr'], ['nya'], ['dia'], ['nya'], ['ia'], ['nya']],\n",
       " [['ai', 'ling', 'ngiam'], ['nya']],\n",
       " [['pt', 'astra', 'otoparts', 'tbk'], ['pt', 'astra', 'otoparts']],\n",
       " [['pt', 'exedy', 'indonesia'], ['pt', 'exedy', 'indonesia']]]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[get_markable_text(b) for b in a] for a in baseline_chains if len(a) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['hartadi', 'a', 'sarwono'],\n",
       "  ['ia'],\n",
       "  ['hartadi'],\n",
       "  ['hartadi'],\n",
       "  ['hartadi'],\n",
       "  ['ia']],\n",
       " [['dirjend',\n",
       "   'industri',\n",
       "   'logam',\n",
       "   'mesin',\n",
       "   'tekstil',\n",
       "   'departemen',\n",
       "   'perindustrian',\n",
       "   'ansari',\n",
       "   'bukhari'],\n",
       "  ['ansari'],\n",
       "  ['ansari']],\n",
       " [['pdb'], ['pdb'], ['pdb']],\n",
       " [['menteri', 'keuangan', 'sri', 'mulyani'],\n",
       "  ['sri', 'mulyani'],\n",
       "  ['mulyani'],\n",
       "  ['mulyani']],\n",
       " [['direktur', 'aali'], ['santosa'], ['nya']],\n",
       " [['miranda', 's', 'goeltom'], ['miranda'], ['miranda'], ['nya'], ['nya']],\n",
       " [['deputi', 'gubernur', 'senior', 'bi'],\n",
       "  ['miranda', 's', 'goeltom'],\n",
       "  ['miranda'],\n",
       "  ['nya']],\n",
       " [['direktur', 'teknologi', 'dan', 'operasional', 'bank', 'mandiri'],\n",
       "  ['sasmita'],\n",
       "  ['dia'],\n",
       "  ['ia'],\n",
       "  ['nya']],\n",
       " [['bank', 'mandiri'],\n",
       "  ['nya'],\n",
       "  ['kami'],\n",
       "  ['bank', 'mandiri'],\n",
       "  ['bank', 'mandiri'],\n",
       "  ['nya']],\n",
       " [['menko', 'perekonomian', 'boediono'], ['nya'], ['boediono'], ['nya']],\n",
       " [['menteri', 'keuangan', 'sri', 'mulyani', 'indrawati'], ['nya'], ['nya']],\n",
       " [['analis', 'pefindo', 'ronald', 'hertanto'], ['nya'], ['dia']],\n",
       " [['trje'], ['trje'], ['trje']],\n",
       " [['jel'], ['jel']],\n",
       " [['adb'], ['adb'], ['adb']],\n",
       " [['direktur', 'pendanaan', 'luar', 'negeri', 'multilateral', 'bappenas'],\n",
       "  ['rm', 'dewo', 'broto', 'joko', 'p'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['dewo']],\n",
       " [['sekretaris', 'perusahaan', 'bakrie', 'sumatera', 'plantations', 'tbk'],\n",
       "  ['fitri', 'barnas'],\n",
       "  ['nya'],\n",
       "  ['ia']],\n",
       " [['pt', 'nibung', 'arthamulia'], ['pt', 'nibung', 'arthamulia']],\n",
       " [['dpr'], ['dpr']],\n",
       " [['dirjen',\n",
       "   'bea',\n",
       "   'dan',\n",
       "   'cukai',\n",
       "   'departemen',\n",
       "   'keuangan',\n",
       "   'anwar',\n",
       "   'suprijad'],\n",
       "  ['anwar', 'suprijad'],\n",
       "  ['anwar'],\n",
       "  ['nya'],\n",
       "  ['dia'],\n",
       "  ['nya'],\n",
       "  ['ia']],\n",
       " [['indonesia'], ['nya']],\n",
       " [['lembaga', 'pemeringkat', 'internasional', 'fitch', 'ratings'],\n",
       "  ['fitch'],\n",
       "  ['fitch']],\n",
       " [['ai', 'ling', 'ngiam'], ['nya'], ['nya'], ['nya'], ['nya']],\n",
       " [['pt', 'astra', 'otoparts', 'tbk'],\n",
       "  ['nya'],\n",
       "  ['kami'],\n",
       "  ['pt', 'astra', 'otoparts']],\n",
       " [['pt', 'exedy', 'indonesia'],\n",
       "  ['exedy', 'corporation'],\n",
       "  ['pt', 'exedy', 'indonesia'],\n",
       "  ['exedy', 'corporation']],\n",
       " [['sekretaris', 'perusahaan', 'astra', 'otoparts'],\n",
       "  ['kartina', 'rahayu'],\n",
       "  ['dia'],\n",
       "  ['dia'],\n",
       "  ['nya']],\n",
       " [['menkeu', 'sri', 'mulyani', 'indrawati'], ['dia']]]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[get_markable_text(b) for b in a] for a in label_chains if len(a) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python TA",
   "language": "python",
   "name": "ta-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
